---
layout: archive
title: ""
permalink: /research/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Security of machine learning system
======
Studies have showed that machine learning models, not only neural networks, are vulnerable to adversarial examples. Although adversarial robustness have been extensively studied in the context of neural networks, research on this issue in many other machine learning and statistical models and how to make these models robust against adversarial examples is still limited. It is thus interesting to study how to attack and defend these models.

I also plan to continue study how to make deep learning models more robust and resistant against adversarial attacks. Previously, we mainly focused on deep learning models on image dataset, i.e. the security of deep neural net in computer vision. As deep neural networks have demonstrated state-of-the-art performances on many difficult machine learning tasks, such as natural language processing (NLP). With the widely application of deep neural nets in many NLP tasks, it is also worth studying the security issue of deep neural nets in the field of natural language processing.

New machine learning and statistical model
======
Another line of research I would like to continue working on is designing models with better statistical guarantees. In previous works, we developed efficient and scalable machine learning and statistical models to solve real-world problems. There are many problems remain unsolved in this field, such as better ranking models with statistical guarantee, more ''fair'' machine learning models in dealing with biased data and so on.

